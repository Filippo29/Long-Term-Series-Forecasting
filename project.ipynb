{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: ['mpi_roof_2023b.csv', 'mpi_roof_2023a.csv']\n",
      "Found a total of 52700 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippo/Desktop/progetto nn/Long-Term-Series-Forecasting/weather/dataset.py:69: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  dates_df['month'] = dates_df[\"Date Time\"].apply(lambda row:row.month,1)\n",
      "/Users/filippo/Desktop/progetto nn/Long-Term-Series-Forecasting/weather/dataset.py:70: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  dates_df['day'] = dates_df[\"Date Time\"].apply(lambda row:row.day,1)\n",
      "/Users/filippo/Desktop/progetto nn/Long-Term-Series-Forecasting/weather/dataset.py:71: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  dates_df['weekday'] = dates_df[\"Date Time\"].apply(lambda row:row.weekday(),1)\n",
      "/Users/filippo/Desktop/progetto nn/Long-Term-Series-Forecasting/weather/dataset.py:72: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  dates_df['hour'] = dates_df[\"Date Time\"].apply(lambda row:row.hour,1)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from weather.dataset import weather_dataset\n",
    "\n",
    "dataset = weather_dataset()\n",
    "\n",
    "train_set, test_set, valid_set = dataset.split()\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 7., 22.,  5., 18.],\n",
      "         [ 7., 22.,  5., 18.],\n",
      "         [ 7., 22.,  5., 18.],\n",
      "         ...,\n",
      "         [ 7., 24.,  0., 19.],\n",
      "         [ 7., 24.,  0., 20.],\n",
      "         [ 7., 24.,  0., 20.]]]), tensor([[[986.7100,  22.5800, 296.8600,  ..., 325.5400,  34.2500, 408.3000],\n",
      "         [986.6600,  22.6000, 296.8900,  ..., 295.6100,  34.1000, 408.4000],\n",
      "         [986.6300,  22.5700, 296.8600,  ..., 329.1500,  33.9600, 408.7000],\n",
      "         ...,\n",
      "         [977.1000,  16.8800, 291.9600,  ...,  75.2300,  29.8400, 417.2000],\n",
      "         [977.1200,  16.9100, 291.9900,  ...,  45.3100,  29.5900, 416.8000],\n",
      "         [977.2100,  16.8600, 291.9300,  ...,  20.7100,  29.3800, 417.5000]]],\n",
      "       dtype=torch.float64), tensor([[[ 7., 24.,  0., 20.],\n",
      "         [ 7., 24.,  0., 20.],\n",
      "         [ 7., 24.,  0., 20.],\n",
      "         [ 7., 24.,  0., 20.],\n",
      "         [ 7., 24.,  0., 21.],\n",
      "         [ 7., 24.,  0., 21.],\n",
      "         [ 7., 24.,  0., 21.],\n",
      "         [ 7., 24.,  0., 21.],\n",
      "         [ 7., 24.,  0., 21.],\n",
      "         [ 7., 24.,  0., 21.],\n",
      "         [ 7., 24.,  0., 22.],\n",
      "         [ 7., 24.,  0., 22.],\n",
      "         [ 7., 24.,  0., 22.],\n",
      "         [ 7., 24.,  0., 22.],\n",
      "         [ 7., 24.,  0., 22.],\n",
      "         [ 7., 24.,  0., 22.],\n",
      "         [ 7., 24.,  0., 23.],\n",
      "         [ 7., 24.,  0., 23.],\n",
      "         [ 7., 24.,  0., 23.],\n",
      "         [ 7., 24.,  0., 23.],\n",
      "         [ 7., 24.,  0., 23.],\n",
      "         [ 7., 24.,  0., 23.],\n",
      "         [ 7., 25.,  1.,  0.],\n",
      "         [ 7., 25.,  1.,  0.],\n",
      "         [ 7., 25.,  1.,  0.],\n",
      "         [ 7., 25.,  1.,  0.],\n",
      "         [ 7., 25.,  1.,  0.],\n",
      "         [ 7., 25.,  1.,  0.],\n",
      "         [ 7., 25.,  1.,  1.],\n",
      "         [ 7., 25.,  1.,  1.],\n",
      "         [ 7., 25.,  1.,  1.],\n",
      "         [ 7., 25.,  1.,  1.],\n",
      "         [ 7., 25.,  1.,  1.],\n",
      "         [ 7., 25.,  1.,  1.],\n",
      "         [ 7., 25.,  1.,  2.],\n",
      "         [ 7., 25.,  1.,  2.],\n",
      "         [ 7., 25.,  1.,  2.],\n",
      "         [ 7., 25.,  1.,  2.],\n",
      "         [ 7., 25.,  1.,  2.],\n",
      "         [ 7., 25.,  1.,  2.],\n",
      "         [ 7., 25.,  1.,  3.],\n",
      "         [ 7., 25.,  1.,  3.],\n",
      "         [ 7., 25.,  1.,  3.],\n",
      "         [ 7., 25.,  1.,  3.],\n",
      "         [ 7., 25.,  1.,  3.],\n",
      "         [ 7., 25.,  1.,  3.],\n",
      "         [ 7., 25.,  1.,  4.],\n",
      "         [ 7., 25.,  1.,  4.],\n",
      "         [ 7., 25.,  1.,  4.],\n",
      "         [ 7., 25.,  1.,  4.],\n",
      "         [ 7., 25.,  1.,  4.],\n",
      "         [ 7., 25.,  1.,  4.],\n",
      "         [ 7., 25.,  1.,  5.],\n",
      "         [ 7., 25.,  1.,  5.],\n",
      "         [ 7., 25.,  1.,  5.],\n",
      "         [ 7., 25.,  1.,  5.],\n",
      "         [ 7., 25.,  1.,  5.],\n",
      "         [ 7., 25.,  1.,  5.],\n",
      "         [ 7., 25.,  1.,  6.],\n",
      "         [ 7., 25.,  1.,  6.],\n",
      "         [ 7., 25.,  1.,  6.],\n",
      "         [ 7., 25.,  1.,  6.],\n",
      "         [ 7., 25.,  1.,  6.],\n",
      "         [ 7., 25.,  1.,  6.],\n",
      "         [ 7., 25.,  1.,  7.],\n",
      "         [ 7., 25.,  1.,  7.],\n",
      "         [ 7., 25.,  1.,  7.],\n",
      "         [ 7., 25.,  1.,  7.],\n",
      "         [ 7., 25.,  1.,  7.],\n",
      "         [ 7., 25.,  1.,  7.],\n",
      "         [ 7., 25.,  1.,  8.],\n",
      "         [ 7., 25.,  1.,  8.],\n",
      "         [ 7., 25.,  1.,  8.],\n",
      "         [ 7., 25.,  1.,  8.],\n",
      "         [ 7., 25.,  1.,  8.],\n",
      "         [ 7., 25.,  1.,  8.],\n",
      "         [ 7., 25.,  1.,  9.],\n",
      "         [ 7., 25.,  1.,  9.],\n",
      "         [ 7., 25.,  1.,  9.],\n",
      "         [ 7., 25.,  1.,  9.],\n",
      "         [ 7., 25.,  1.,  9.],\n",
      "         [ 7., 25.,  1.,  9.],\n",
      "         [ 7., 25.,  1., 10.],\n",
      "         [ 7., 25.,  1., 10.],\n",
      "         [ 7., 25.,  1., 10.],\n",
      "         [ 7., 25.,  1., 10.],\n",
      "         [ 7., 25.,  1., 10.],\n",
      "         [ 7., 25.,  1., 10.],\n",
      "         [ 7., 25.,  1., 11.],\n",
      "         [ 7., 25.,  1., 11.],\n",
      "         [ 7., 25.,  1., 11.],\n",
      "         [ 7., 25.,  1., 11.],\n",
      "         [ 7., 25.,  1., 11.],\n",
      "         [ 7., 25.,  1., 11.],\n",
      "         [ 7., 25.,  1., 12.],\n",
      "         [ 7., 25.,  1., 12.],\n",
      "         [ 7., 25.,  1., 12.],\n",
      "         [ 7., 25.,  1., 12.],\n",
      "         [ 7., 25.,  1., 12.],\n",
      "         [ 7., 25.,  1., 12.]]]), tensor([[[977.2800,  16.9200, 291.9800,  ...,   9.1800,  29.1800, 417.7000],\n",
      "         [977.3600,  16.9100, 291.9700,  ...,   3.6500,  28.9800, 418.8000],\n",
      "         [977.5400,  16.7100, 291.7500,  ...,   1.1800,  28.7800, 420.3000],\n",
      "         ...,\n",
      "         [978.4500,  14.9300, 289.8800,  ..., 358.3100,  27.2000, 413.8000],\n",
      "         [978.3300,  15.1600, 290.1200,  ..., 427.8000,  27.1400, 413.7000],\n",
      "         [978.2500,  15.4500, 290.4200,  ..., 496.6900,  27.1900, 415.7000]]],\n",
      "       dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for e in train_loader:\n",
    "    print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "\n",
    "model = MICN(dataset.seq_len, dataset.pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400, 256]) torch.Size([400, 256]) torch.Size([1, 400, 256])\n",
      "torch.Size([1, 400, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (400) must match the size of tensor b (399) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nn_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nn_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/progetto nn/Long-Term-Series-Forecasting/model.py:250\u001b[0m, in \u001b[0;36mMICN.forward\u001b[0;34m(self, x, x_time_tokens, y_time_tokens)\u001b[0m\n\u001b[1;32m    247\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(Xs, torch\u001b[38;5;241m.\u001b[39mcat([x_time_tokens, y_time_tokens], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mprint\u001b[39m(embedded\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 250\u001b[0m dec_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_trans\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m dec_out \u001b[38;5;241m=\u001b[39m dec_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len:, :] \u001b[38;5;241m+\u001b[39m Yt[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len:, :]\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dec_out\n",
      "File \u001b[0;32m~/miniforge3/envs/nn_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nn_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/progetto nn/Long-Term-Series-Forecasting/model.py:223\u001b[0m, in \u001b[0;36mSeasonal_Prediction.forward\u001b[0;34m(self, dec)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, dec):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mic_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmic:\n\u001b[0;32m--> 223\u001b[0m         dec \u001b[38;5;241m=\u001b[39m \u001b[43mmic_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(dec)\n",
      "File \u001b[0;32m~/miniforge3/envs/nn_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nn_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/progetto nn/Long-Term-Series-Forecasting/model.py:199\u001b[0m, in \u001b[0;36mMIC.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m    197\u001b[0m multi \u001b[38;5;241m=\u001b[39m []  \n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_kernel)):\n\u001b[0;32m--> 199\u001b[0m     src_out, trend1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecomp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     src_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_trans_conv(src_out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_trans[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misometric_conv[i])\n\u001b[1;32m    201\u001b[0m     multi\u001b[38;5;241m.\u001b[39mappend(src_out)  \n",
      "File \u001b[0;32m~/miniforge3/envs/nn_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nn_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/progetto nn/Long-Term-Series-Forecasting/model.py:111\u001b[0m, in \u001b[0;36mseries_decomp.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    110\u001b[0m     moving_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoving_avg(x)\n\u001b[0;32m--> 111\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmoving_mean\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res, moving_mean\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (400) must match the size of tensor b (399) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for e in train_loader:\n",
    "    print(model(e[1], e[0], e[2]).shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
